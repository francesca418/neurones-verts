# -*- coding: utf-8 -*-
"""fr-ngram.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14K-njo1JoSZk4T6A2QZDU8k5CnHGi1Mn
"""

!pip install --upgrade nltk

from nltk.util import bigrams
from nltk import RegexpTokenizer
from nltk.lm.preprocessing import flatten, pad_both_ends, padded_everygram_pipeline
from nltk.lm import MLE

toknizer = RegexpTokenizer(r'''\w'|\w+|[^\w\s]''')

!wget https://raw.githubusercontent.com/UniversalDependencies/UD_French-GSD/master/fr_gsd-ud-train.conllu

# get all sentences in plaintext
# path should be something like "fr_gsd-ud-train.conllu"
def get_training_sentences(pathname):
    with open(pathname) as f:
        lines = f.readlines()
        text = filter(lambda x: x.startswith("# text"), lines)
        text = [sent.strip()[9:] for sent in text]
        return text

with open("fr_gsd-ud-train.conllu") as f:
    lines = f.readlines()
    text = filter(lambda x: x.startswith("# text"), lines)
    text = [sent[9:] for sent in text]
    print(len(text))
    text = [toknizer.tokenize(sent) for sent in text]

from collections import Counter

with open("fr_gsd-ud-train.conllu") as f:
    c = Counter()
    lines = f.read()
    lines = lines.split("# sent_id =")
    columns = ["ID", "FORM", "LEMMA", "UPOS", "XPOS", "FEATS", "HEAD", "DEPREL", "DEPS", "MISC"]
    feature_list = ["Gender", "VerbForm"]

    entries = lines[1:]
    for entry in entries:
        entry = entry.strip()
        dicts = [{}]
        entry_lines = entry.split("\n")
        sentence = entry_lines[1]
        entry_lines = entry_lines[2:]

        for line in entry_lines:
            cols = line.split("\t")

            if cols[0].isnumeric():
                feats = cols[5]

                all_feats = feats.split("|")
                feat_values = set(f for f in all_feats if f.split("=")[0] in feature_list)
                cols[5] = feat_values
                zipped = zip(columns, cols)
                d = dict(tup for tup in zipped)

                dicts.append(d)
        
        for d in dicts[1:]:
            head = d["HEAD"]
            if head.isnumeric():
                head_dict = dicts[int(head)]
                if head_dict and d['FEATS'] and d["FEATS"] == head_dict["FEATS"] and abs(int(d['ID']) - int(head)) > 3:
                    construction = []
                    x = int(d['ID'])
                    y = int(head)
                    if x > y:
                        x, y = y, x
                    y = y + 1
                    for i in range(x, y):
                        tok = dicts[i]
                        construction.append(tok['UPOS'])
                    c.update([tuple(construction)])
        '''for d in dicts[1:]:
            if d['UPOS'] == 'ADJ' and 'Gender=Fem' in d['FEATS']:
                c.update([d['LEMMA']])'''

with open("fr_gsd-ud-train.conllu") as f:
    lines = f.read()
    lines = lines.split("# sent_id =")
    columns = ["ID", "FORM", "LEMMA", "UPOS", "XPOS", "FEATS", "HEAD", "DEPREL", "DEPS", "MISC"]
    feature_list = ["Gender", "VerbForm"]

    cons = [x for (x,y) in c.most_common(50)]
    #valid_cons = cons.copy()
    valid = [('VERB', 'DET', 'NOUN', 'CCONJ', 'ADP', 'VERB'), ('VERB', 'DET', 'NUM', 'NOUN', 'NUM', 'ADP', 'PROPN', 'CCONJ', 'VERB'), ('PRON', 'ADV', 'AUX', 'ADV', 'ADJ'), ('VERB', 'ADP', 'PROPN', 'DET', 'NUM', 'NOUN', 'NUM', 'CCONJ', 'VERB'), ('VERB', 'DET', 'NUM', 'NOUN', 'NUM', 'CCONJ', 'VERB'), ('VERB', 'DET', 'NUM', 'NOUN', 'NUM', 'ADP', 'PROPN', 'PROPN', 'PUNCT', 'CCONJ', 'VERB'), ('DET', 'ADJ', 'CCONJ', 'ADJ', 'NOUN'), ('ADJ', 'SCONJ', 'AUX', 'DET', 'NOUN'), ('VERB', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'CCONJ', 'VERB'), ('PRON', 'ADP', 'DET', 'ADV', 'ADJ', 'NOUN'), ('VERB', 'NUM', 'NOUN', 'CCONJ', 'VERB')]

    entries = lines[1:]
    for entry in entries:
        entry = entry.strip()
        dicts = [{}]
        entry_lines = entry.split("\n")
        sentence = entry_lines[1]
        entry_lines = entry_lines[2:]

        for line in entry_lines:
            cols = line.split("\t")

            if cols[0].isnumeric():
                feats = cols[5]

                all_feats = feats.split("|")
                feat_values = set(f for f in all_feats if f.split("=")[0] in feature_list)
                cols[5] = feat_values
                zipped = zip(columns, cols)
                d = dict(tup for tup in zipped)

                dicts.append(d)

        '''for con in cons:
            length = len(con)
            end = len(dicts) - length
            if end > 0:
                for i in range(1, end):
                    parts = [d['UPOS'] for d in dicts[i:end]]
                    if tuple(parts) == con:
                        cue = (dicts[i])
                        target = (dicts[end-1])
                        if cue['FEATS'] and target['FEATS']:
                            if cue['FEATS'] != target['FEATS']:
                                if con in valid_cons:
                                    valid_cons.remove(con)'''
        for con in valid:
            length = len(con)
            end = len(dicts) - length
            if end > 0:
                for i in range(1, end):
                    parts = [d['UPOS'] for d in dicts[i:end]]
                    if tuple(parts) == con:
                        print(con)
                        print(i)
                        print(dicts[i]['FORM'])
                        print(sentence)


    print(valid_cons)
    print(len(valid_cons))

    con_set = set()
    for con in valid_cons:
        l = list(con)
        if 'PUNCT' in con:
            l.remove('PUNCT')
        con_set.add(tuple(l))
    print(con_set)

train, vocab = padded_everygram_pipeline(5, text)

lm = MLE(5)

lm.fit(train, vocab)
print(lm.vocab)
# <Vocabulary with cutoff=1 unk_label='<UNK>' and 9 items>
print(len(lm.vocab))

lm.generate(5, text_seed=['La'])

test_string = "La banane dans le chapeau"
t1 = "elle"
t2 = "elles"

print(lm.score(t1, ["La", "banane"]))
print(lm.score(t2, ["La", "banane"]))

print(lm.counts)

sorted(lm.counts[['la']].items())

from collections import defaultdict

# defining test cases
test_cases = [
    ("elle est très", "intelligente", "intelligent"),
    ("l'information politique est", "codée", "codé"),
    ("ils deviennent chevaliers du bien", "chargés", "chargé"),
    ("la fille qui achète le chapeau est", "heureuse", " heureux"),
    ("le chien qui mange des pommes est", "petit", "petite"),
    ("la ville qui est petite a été", "construite", "construit"),
    ("le temps de la ville est très", "froid", "froide"),
    ("les droits de les hommes sont très", "grands", "grande"),
    ("la région du pays est", "grande", "grand"),
    ("Le 50 États a été", "envahi", "envahie"),
    ("Si les 32 États qui n'avaient pas une limite avaient", "adopté", "adoptée"),
    ("C'est de cette société que des conditions radicalement nouvelles ont été", "imposées", "imposés"),
    ("le premier jour du film était très", "chaud", "chaudes"),
    ("la collection la plus riche est", "celle", "celui"),
    ("le plus gros marchand d'armes est", "celui", "celle"),
    ("la plus petite collection au monde est", "celle", "celui"),
    ("le seul département de la région est", "celui", "celle")
]


# score dictionary helper function (implement this)
def get_scores(prompt: str, word1, word2) -> defaultdict:

    # note: values don't need to be probability mass (can be logits or any real value instead)
    #       relative order just has to be preserved between predictions
    p1 = 0.0
    words1 = toknizer.tokenize(prompt)
    words2 = words1.copy()

    '''while p1 == 0.0 and words1:
        p1 = lm.score(word1, words1)
        words1.pop(0)'''
    if p1 == 0.0:
        p1 = lm.score(word1)

    p2 = 0.0
    words = prompt.split(" ")
    '''while p2 == 0.0 and words2:
        p2 = lm.score(word2, words2)
        words2.pop(0)'''
    if p2 == 0.0:
        p2 = lm.score(word2)
    
    scores = {word1: p1, word2: p2}
    return scores


# note: `get_scores` is a function
def get_accuracy(get_scores, test_cases):
    valid_cases, correct_cases = 0.0, 0.0
    for prompt, pred_correct, pred_incorrect in test_cases:
        scores = get_scores(prompt, pred_correct, pred_incorrect)
        if scores[pred_correct] > scores[pred_incorrect]:
            valid_cases += 1
            correct_cases += 1
        elif scores[pred_correct] < scores[pred_incorrect]:
            valid_cases += 1

    return correct_cases / valid_cases


print(get_accuracy(get_scores, test_cases))

lm.score('celle')
toknizer.tokenize('celle-ci')